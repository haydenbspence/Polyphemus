<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.361">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Background</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../background/index.html" rel="" target="" aria-current="page">
 <span class="menu-text">Background</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../models/index.html" rel="" target="">
 <span class="menu-text">Models</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-references" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">References</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-references">    
        <li>
    <a class="dropdown-item" href="../references/index.html" rel="" target=""><i class="bi bi-question-circle" role="img">
</i> 
 <span class="dropdown-text">FAQ</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../references/defs.html" rel="" target="">
 <span class="dropdown-text">Definitions</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../blog/index.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Background</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Large Language Models (LLMs) represent a cutting-edge advancement in the field of artificial intelligence, specifically within natural language processing (NLP). These models are designed to understand and generate human-like text, exhibiting an impressive capacity for language comprehension and creation. Built on the principles of machine learning, LLMs, like OpenAI’s GPT-3 or GPT-4, are trained on vast amounts of data, allowing them to predict and generate coherent and contextually appropriate responses. From enhancing user experiences in chatbots, to generating content, and assisting with language translation, LLMs are revolutionizing how we interact with technology, offering an increasingly nuanced interface that blends AI sophistication with the complexities of human language.</p>
</section>
<section id="timeline" class="level1">
<h1>Timeline</h1>
<p>Our objective in presenting this timeline of events is to highlight the swift progress and growing democratization in the field of open-source AI and application of LLMs. In doing so, we hope to demonstrate the feasibility and opportunities for applications in the area of health informatics and data science. This timeline primarily focuses on open-source technologies and open-science research that have practical, working examples, rather than emphasizing cutting-edge institutional research breakthroughs or proprietary advancements.<br>
</p>
<table class="table">
<thead>
<tr class="header">
<th>Date</th>
<th>Event</th>
<th>Significance and Implications</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2022-10-17</td>
<td><p><a href="https://github.com/hwchase17/langchain/blob/master/CITATION.cff">Chase Harrison releases LangChain</a>, a python library that assists in the development of applications that combine LLMs and other sources of knowledge.</p>
<p>“We believe that the most powerful and differentiated applications will not only call out to a language model, but will also be <em>Data-aware</em> and <em>Agentic</em>.</p></td>
<td>LangChain lowers the barrier to integrating disparate sources and discrete LLMs. This allows for interdisciplinary and more sophisticated networking of data sources and LLMs.</td>
</tr>
<tr class="even">
<td>2023-02-24</td>
<td><a href="https://ai.facebook.com/blog/large-language-model-llama-meta-ai/">Meta launches Large Language Model Meta AI (LLaMA) and open sources code without model weights.</a></td>
<td>Meta’s decision to release all of the source code for their AI, while withholding the weights, does illustrate a degree of commitment to open-source principles among major tech firms. However, the exclusion of the weights from this release signifies a cautious approach, emphasizing the proprietary value that these weights contribute to the effectiveness of LLMs.</td>
</tr>
<tr class="odd">
<td>2023-03-03</td>
<td><a href="https://web.archive.org/web/20230603194841/https://www.vice.com/en/article/xgwqgw/facebooks-powerful-large-language-model-leaks-online-4chan-llama">LLaMA weights are leaked and shared via torrent on the internet.</a></td>
<td>The leak of Meta’s LLaMA weights raises the potential of misuse of AI technology, disrupts the control and security of this technology, highlights legal issues. Importantly, it also spurs AI research and development by universities and open-source communities.</td>
</tr>
<tr class="even">
<td>2023-03-12</td>
<td><a href="https://github.com/ggerganov/llama.cpp/issues/58">Artem Andreenko is able to get LLaMA working the a Raspberry Pi</a></td>
<td><p>Andreenko’s report of being able to run LLaMA on inexpensive consumer-level hardware like the Raspberry Pi 4 demonstrates the potential for the democratization of AI. High-end resources present a barrier to who can implement, and especially who can fine-tune, LLMs. Lowering this barrier means localized solutions, hobbyist tinkering, and innovation will involve a broader segment of the population.</p>
<p>Although the implementation of LLMs on this level of hardware is slow and impractical for the majority of use-cases, the energy efficiency aspect is also promising as AI tends to have high energy consumption.</p></td>
</tr>
<tr class="odd">
<td>2023-03-13</td>
<td><a href="https://crfm.stanford.edu/2023/03/13/alpaca.html">Stanford releases Alpaca, the first minimal working example of fine-tuning LLaMA</a></td>
<td></td>
</tr>
<tr class="even">
<td>2023-03-14</td>
<td>Eric Wang releases <a href="https://github.com/tloen/alpaca-lora">Alpaca-LoRA</a></td>
<td></td>
</tr>
<tr class="odd">
<td>2023-03-19</td>
<td>The <a href="https://lmsys.org/blog/2023-03-30-vicuna/">Vicuna</a> project trained a model on high-quality ChatGPT dialogues sourced from sites such as <a href="https://sharegpt.com/">ShareGPT</a>.</td>
<td>Cost of Training: ~$300</td>
</tr>
<tr class="even">
<td>2023-03-25</td>
<td>Nomic releases GPT4All</td>
<td></td>
</tr>
<tr class="odd">
<td>2023-03-03</td>
<td><a href="https://www.cerebras.net/">Cerebras</a> trained the GPT-3 architecture using the optimal compute schedule implied by Chinchilla and the optimal scaling implied by <a href="https://arxiv.org/abs/2203.03466">μ-parameterization</a>. This marked the first example of a model that outperformed GPT-3 and was trained from scratch. Consequently, the open source community gained full access to two fLLMs that rival GPT4 and PaLM2.</td>
<td></td>
</tr>
<tr class="even">
<td>2023-03-28</td>
<td>LLaMA-Adapter uses Parameter Efficient Fine Tuning (PEFT), the project introduced instruction tuning and multimodality in a mere hour of training, establishing a new state-of-the-art (SOTA) for Science Q&amp;A.</td>
<td></td>
</tr>
<tr class="odd">
<td>2023-04-03</td>
<td>The <a href="https://bair.berkeley.edu/blog/2023/04/03/koala/">Koala</a> project released a model trained on open source data. When evaluated against ChatGPT with human subjects, over 50% of users either preferred Koala responses or expressed no preference between the two. The training cost was approximately $100.</td>
<td>Cost of Training: ~$100</td>
</tr>
<tr class="even">
<td>2023-04-15</td>
<td>The Open Assistant project launched a <a href="https://arxiv.org/pdf/2304.07327.pdf">model and dataset</a>for Alignment via Real Life Human Feedback (RLHF). Their model closely competed with ChatGPT in terms of human preference (48.3% vs.&nbsp;51.7%). The dataset could also be applied to Pythia-12B, and a complete open-source technology stack was provided to run the model. This publicly available dataset made RLHF feasible for individual users.</td>
<td>Cost of Training: ~$100</td>
</tr>
<tr class="odd">
<td></td>
<td><a href="https://github.com/jerryjliu/llama_index">LLamaIndex</a></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>GPTCache</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>LocalAI</td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>PandasAI</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>GPT-Q for LLaMA</td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>Large Language Model Activation-aware Weight Quantization (LLM-AWQ)</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>Microsoft Guidance</td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>Simple-LLM-Finetuner</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>The Paper <a href="https://arxiv.org/pdf/2304.03442.pdf"><em>Generative Agents: Interactive Simulacra of Human Behavior</em></a>is implemented by <a href="https://quangbk.github.io/">Pham Tran Minh Quang</a> using LangChain and uploaded to GitHub (<a href="https://github.com/QuangBK/generativeAgent_LLM">generativeAgent_LLM</a>) with an accompanying <a href="https://betterprogramming.pub/implement-generative-agent-with-local-llm-guidance-and-langchain-full-features-fa57655f3de1">article</a>.</td>
<td></td>
</tr>
</tbody>
</table>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="../about/index.html">About</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../faq/index.qmd">FAQ</a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://google.com">
      <i class="bi bi-github" role="img" aria-label="Polyphemus GitHub">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>



</body></html>