[
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "About",
    "section": "",
    "text": "The Observational Medical Outcomes Partnership (OMOP) is strategically positioned to profoundly influence the application of artificial intelligence (AI) to open science and observational medical research. An internal Google document leaked in early May 2023 underscores the potential of Open Source AI to outperform major technology firms in the sector. Open source and open science possess significant advantages over private entities and institutions, primarily the capability to organically set standards, foster collaboration, and enhance interoperability. The Polyphemus Project is an innovative proposal aimed at replicating and tailoring cutting-edge advancements in Open Source AI to suit the needs of observational medical research. By establishing comprehensive frameworks, offering educational materials, conducting evaluations, and providing infrastructural access, the project aspires to facilitate and encourage the integration and development of open-source AI tools and methodologies within the OHDSI community. This approach stands to democratize AI, advancing the field while bolstering the quality and inclusivity of observational medical research."
  },
  {
    "objectID": "about/index.html#abstract",
    "href": "about/index.html#abstract",
    "title": "About",
    "section": "",
    "text": "The Observational Medical Outcomes Partnership (OMOP) is strategically positioned to profoundly influence the application of artificial intelligence (AI) to open science and observational medical research. An internal Google document leaked in early May 2023 underscores the potential of Open Source AI to outperform major technology firms in the sector. Open source and open science possess significant advantages over private entities and institutions, primarily the capability to organically set standards, foster collaboration, and enhance interoperability. The Polyphemus Project is an innovative proposal aimed at replicating and tailoring cutting-edge advancements in Open Source AI to suit the needs of observational medical research. By establishing comprehensive frameworks, offering educational materials, conducting evaluations, and providing infrastructural access, the project aspires to facilitate and encourage the integration and development of open-source AI tools and methodologies within the OHDSI community. This approach stands to democratize AI, advancing the field while bolstering the quality and inclusivity of observational medical research."
  },
  {
    "objectID": "background/index.html",
    "href": "background/index.html",
    "title": "Background",
    "section": "",
    "text": "Introduction\nLarge Language Models (LLMs) represent a cutting-edge advancement in the field of artificial intelligence, specifically within natural language processing (NLP). These models are designed to understand and generate human-like text, exhibiting an impressive capacity for language comprehension and creation. Built on the principles of machine learning, LLMs, like OpenAI’s GPT-3 or GPT-4, are trained on vast amounts of data, allowing them to predict and generate coherent and contextually appropriate responses. From enhancing user experiences in chatbots, to generating content, and assisting with language translation, LLMs are revolutionizing how we interact with technology, offering an increasingly nuanced interface that blends AI sophistication with the complexities of human language.\n\n\nTimeline\nOur objective in presenting this timeline of events is to highlight the swift progress and growing democratization in the field of open-source AI and application of LLMs. In doing so, we hope to demonstrate the feasibility and opportunities for applications in the area of health informatics and data science. This timeline primarily focuses on open-source technologies and open-science research that have practical, working examples, rather than emphasizing cutting-edge institutional research breakthroughs or proprietary advancements.\n\n\n\n\nDate\nEvent\nSignificance and Implications\n\n\n\n\n2022-10-17\nChase Harrison releases LangChain, a python library that assists in the development of applications that combine LLMs and other sources of knowledge.\n“We believe that the most powerful and differentiated applications will not only call out to a language model, but will also be Data-aware and Agentic.\nLangChain lowers the barrier to integrating disparate sources and discrete LLMs. This allows for interdisciplinary and more sophisticated networking of data sources and LLMs.\n\n\n2023-02-24\nMeta launches Large Language Model Meta AI (LLaMA) and open sources code without model weights.\nMeta’s decision to release all of the source code for their AI, while withholding the weights, does illustrate a degree of commitment to open-source principles among major tech firms. However, the exclusion of the weights from this release signifies a cautious approach, emphasizing the proprietary value that these weights contribute to the effectiveness of LLMs.\n\n\n2023-03-03\nLLaMA weights are leaked and shared via torrent on the internet.\nThe leak of Meta’s LLaMA weights raises the potential of misuse of AI technology, disrupts the control and security of this technology, highlights legal issues. Importantly, it also spurs AI research and development by universities and open-source communities.\n\n\n2023-03-12\nArtem Andreenko is able to get LLaMA working the a Raspberry Pi\nAndreenko’s report of being able to run LLaMA on inexpensive consumer-level hardware like the Raspberry Pi 4 demonstrates the potential for the democratization of AI. High-end resources present a barrier to who can implement, and especially who can fine-tune, LLMs. Lowering this barrier means localized solutions, hobbyist tinkering, and innovation will involve a broader segment of the population.\nAlthough the implementation of LLMs on this level of hardware is slow and impractical for the majority of use-cases, the energy efficiency aspect is also promising as AI tends to have high energy consumption.\n\n\n2023-03-13\nStanford releases Alpaca, the first minimal working example of fine-tuning LLaMA\n\n\n\n2023-03-14\nEric Wang releases Alpaca-LoRA\n\n\n\n2023-03-19\nThe Vicuna project trained a model on high-quality ChatGPT dialogues sourced from sites such as ShareGPT.\nCost of Training: ~$300\n\n\n2023-03-25\nNomic releases GPT4All\n\n\n\n2023-03-03\nCerebras trained the GPT-3 architecture using the optimal compute schedule implied by Chinchilla and the optimal scaling implied by μ-parameterization. This marked the first example of a model that outperformed GPT-3 and was trained from scratch. Consequently, the open source community gained full access to two fLLMs that rival GPT4 and PaLM2.\n\n\n\n2023-03-28\nLLaMA-Adapter uses Parameter Efficient Fine Tuning (PEFT), the project introduced instruction tuning and multimodality in a mere hour of training, establishing a new state-of-the-art (SOTA) for Science Q&A.\n\n\n\n2023-04-03\nThe Koala project released a model trained on open source data. When evaluated against ChatGPT with human subjects, over 50% of users either preferred Koala responses or expressed no preference between the two. The training cost was approximately $100.\nCost of Training: ~$100\n\n\n2023-04-15\nThe Open Assistant project launched a model and datasetfor Alignment via Real Life Human Feedback (RLHF). Their model closely competed with ChatGPT in terms of human preference (48.3% vs. 51.7%). The dataset could also be applied to Pythia-12B, and a complete open-source technology stack was provided to run the model. This publicly available dataset made RLHF feasible for individual users.\nCost of Training: ~$100\n\n\n\nLLamaIndex\n\n\n\n\nGPTCache\n\n\n\n\nLocalAI\n\n\n\n\nPandasAI\n\n\n\n\nGPT-Q for LLaMA\n\n\n\n\nLarge Language Model Activation-aware Weight Quantization (LLM-AWQ)\n\n\n\n\nMicrosoft Guidance\n\n\n\n\nSimple-LLM-Finetuner\n\n\n\n\nThe Paper Generative Agents: Interactive Simulacra of Human Behavioris implemented by Pham Tran Minh Quang using LangChain and uploaded to GitHub (generativeAgent_LLM) with an accompanying article."
  },
  {
    "objectID": "blog/posts/2023-06-05-polyphemus-temppost/index.html",
    "href": "blog/posts/2023-06-05-polyphemus-temppost/index.html",
    "title": "Polyphemos Temp Post",
    "section": "",
    "text": "Content Title\nSome content here"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Polyphemus Project",
    "section": "",
    "text": "Introduction\nThe infamous Cyclops, Polyphemus, the son of Poseidon in Greek mythology, met his downfall due to the cunning of the hero, Odysseus. When asked for his name, Odysseus cleverly responded with ‘Nobody.’ Unable to pinpoint the culprit behind his blinding, Polyphemus could not seek revenge, his actions limited to hurling a boulder aimlessly into the sea. It wasn’t until Odysseus revealed his true name that the cyclops was able to enlist his father Poseidon’s divine wrath, highlighting the power of a name.\nSimilarly, in the world of systems integration, the naming of objects is crucial. Each object must have a consistent name across various systems. While the characteristics of the object might change over space and time, the name serves as a constant identifier. With a proper name, actions can be directed effectively, whereas without it, one can only attempt hit-or-miss strategies.\nThe importance of naming extends to the realm of artificial intelligence (AI) systems. Large Language Models (LLMs) such as GPT-3, the driving force behind ChatGPT and OpenAI’s API, exemplify this. These models can perform tasks but lack the ability to recognize specific names within specialized knowledge domains. This limitation hampers their wider application, especially in fields such as observational medical research.\nIntroducing Polyphemus, a network of specialty-trained Large Language Models (LLMs), designed to overcome this limitation. Polyphemus models can not only act but also identify object names within their specialized domain. This project, a collaborative effort between the Observational Health Data Sciences and Informatics (OHDSI) community and Polyphemus, focuses on the exploration of LLMs’ application in open science and observational medical research."
  },
  {
    "objectID": "models/index.html",
    "href": "models/index.html",
    "title": "Models",
    "section": "",
    "text": "Models"
  },
  {
    "objectID": "references/acknowledgements.html",
    "href": "references/acknowledgements.html",
    "title": "Acknowledgements",
    "section": "",
    "text": "Acknowledgements\nGeorgi Gerganov for thier work on llama.cpp"
  },
  {
    "objectID": "references/defs.html",
    "href": "references/defs.html",
    "title": "Definitions and Abbreviations",
    "section": "",
    "text": "Term\nAbbreviation\nDefinition\n\n\n\n\nObservational Health Data Sciences and Informatics\nOHDSI\nAn international organization that improves health outcomes by leveraging observational health data. It fosters collaboration among researchers and institutions, developing open-source tools and methodologies for analyzing and interpreting real-world healthcare data.\n\n\nObservational Medical Outcomes Partnership\nOMOP\nA public-private partnership that advances the science of observational research using real-world data. It develops and promotes standardized methods and tools for analyzing observational healthcare data to assess medical product safety and effectiveness, ultimately informing healthcare decisions.\n\n\nArtificial Intelligence\nAI\nRefers to the field of computer science that focuses on creating intelligent machines capable of performing tasks requiring human intelligence. It employs algorithms and techniques enabling machines to perceive, reason, learn, and make decisions. This leads to applications in various domains, including robotics, natural language processing, and image recognition.\n\n\nArtificial General Intelligence\nAGI\n\n\n\nLarge Language Model Meta AI\nLLaMA\nA state-of-the-art foundational large language model developed by Meta, designed to be smaller and more performant than previous models (as of the 2023-02-24 release).\n\n\nLarge Language Model\nLLM\nA category of foundational models that utilize a neural network architecture known as a transformer to learn from patterns in text data.\n\n\nFoundational Model\nFM\nA category of machine learning models trained on broad data using self-supervision at scale. These models can be adapted to a wide range of downstream tasks.\n\n\nFoundational Large Language Model\nF-LLM\nA language model in its original form, prior to any fine-tuning.\n\n\nApplication Program Interface\nAPI\n\n\n\nState of the Art\nSOTA\nRepresents the highest level of achievement or performance in a specific field or domain at a given time. It encompasses the most advanced, innovative, and cutting-edge approaches, techniques, or technologies surpassing previous benchmarks in quality, accuracy, efficiency, or effectiveness.\n\n\nReal Life Human Feedback\nRLHF\nThe continual retraining of machine learning models, including foundational models, via operant conditioning (reward/punishment) based on human annotators’ preferences for the model’s responses.\n\n\nPretrained Autoencoding Language Model\nPALM\nA type of language model that combines pretraining and autoencoding techniques. It initially pretrains the model on a large corpus of text data to understand underlying language patterns and then employs autoencoding methods to reconstruct the input text, generating meaningful representations and capturing latent language features.\n\n\nGenerative Pretrained Transformer\nGPT\nA deep learning model based on the Transformer architecture, pretrained on a large corpus of text data. It generates coherent and contextually relevant text by leveraging the understanding of language patterns and semantics acquired during pretraining.\n\n\nMinimum Working Example\nMWE\nA concise, simplified version of a program, code snippet, or system demonstrating a specific functionality or problem. It typically includes the essential components and minimum code needed to reproduce the issue or showcase the desired behavior, making it easier for others to understand and troubleshoot the problem.\n\n\nMinimum Reproducible Example\nMRE\nA concise, self-contained version of a problem that can be easily reproduced by others. It includes the minimum amount of code or steps necessary to demonstrate the problem, enabling others to understand, investigate, and potentially resolve the issue more effectively.\n\n\nMinimum Viable Product\nMVP\nThe initial version of a product or service that includes the core features needed to deliver value to early adopters or customers. Designed to gather feedback, validate assumptions, and test the market with minimal development effort, enabling rapid iteration and refinement based on user feedback.\n\n\nHallucinations\n\nA term used to describe fabricated outputs by a foundational model, such as making up a citation.\n\n\nNatural Language Processing\nNLP\nA branch of AI focused on enabling computers to understand, interpret, and generate human language, facilitating applications like chatbots, sentiment analysis, and language translation.\n\n\nConvolutional Neural Network\nCNN\nA deep neural network type processing data with a grid-like structure, like images or text. It uses convolutional layers to extract hierarchical patterns and features, making it suitable for image recognition and computer vision tasks.\n\n\nRecurrent Neural Network\nRNN\nA neural network designed to process sequential data by maintaining a hidden state and looping connections. It can capture temporal dependencies, making it suitable for tasks like natural language processing and speech recognition.\n\n\nTransfer Learning\nTL\nA machine learning technique that uses knowledge learned from one task or domain to improve performance on a related task or domain, enabling faster training and better generalization, especially when labeled data is limited.\n\n\nUnsupervised Learning\nUL\nA machine learning approach where the model learns patterns and structures in data without explicit labels or supervision, allowing it to discover hidden relationships and cluster data. It is commonly used in anomaly detection, dimensionality reduction, and recommendation systems.\n\n\nGenerative Adversarial Network\nGAN\nA neural network framework that pits two models, a generator and a discriminator, against each other in a competitive setting. This allows the generator to learn to create realistic synthetic data and is commonly used for generating images, videos, and audio.\n\n\nReinforcement Learning\nRL\nA branch of machine learning where an agent learns to make decisions or take actions in an environment to maximize rewards. It is frequently used in robotics, game-playing algorithms, and autonomous systems.\n\n\nDeep Learning\nDL\nA subfield of machine learning focusing on developing and training artificial neural networks with multiple layers. These networks can learn and represent complex patterns and relationships in data, making them capable of solving intricate tasks like image recognition and natural language processing.\n\n\nSupport Vector Machine\nSVM\nA supervised machine learning algorithm that classifies data by finding an optimal hyperplane in high-dimensional space, maximizing the separation between different classes. It’s often used for classification and regression tasks with clear decision boundaries.\n\n\nNatural Language Generation\nNLG\nA subset of natural language processing that involves generating human-like text or speech from structured data or predefined templates. It is commonly used in chatbots, automated report generation, and content creation applications.\n\n\nBayesian Networks\nBN\nA probabilistic graphical model that represents relationships between variables using a directed acyclic graph, combined with probability distributions. This allows for reasoning, inference, and decision-making under uncertainty, and it is widely used in expert systems, medical diagnosis, and risk analysis.\n\n\nLong Short-Term Memory\nLSTM\nA type of recurrent neural network architecture designed"
  },
  {
    "objectID": "references/index.html",
    "href": "references/index.html",
    "title": "FAQ",
    "section": "",
    "text": "This is a question?\nThis is an answer"
  }
]