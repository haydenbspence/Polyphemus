[
  {
    "objectID": "background/index.html",
    "href": "background/index.html",
    "title": "Background",
    "section": "",
    "text": "By displaying\n\n\n\n\nEvents from February 24, 2023 to April 15, 2023\n\n\nDate\nEvent\nSignificance\n\n\n\n\n2023-02-24\nMeta launches Large Language Model Meta AI (LLaMA) and open sources code without model weights.\n\n\n\n2023-03-03\nLLaMA weights are leaked and shared via torrent on the internet.\n\n\n\n2023-03-12\nArtem Andreenko is able to get LLaMA working the a Raspberry Pi\n\n\n\n2023-03-13\nStanford releases Alpaca, the first minimal working example of fine-tuning LLaMA\n\n\n\n2023-03-14\nEric Wang releases Alpaca-LoRA\n\n\n\n2023-03-18\n\n\n\n\n2023-03-19\nVicuna\n~$300\n\n\n2023-03-25\nNomic releases GPT4All\n\n\n\n2023-03-03\nCerebras uses μ-parameterization\n\n\n\n2023-03-28\nLLaMA-Adapter uses Parameter Efficient Fine Tuning (PEFT)\n\n\n\n2023-04-03\nKoala\n\n\n\n2023-04-15\nOpen Assistant https://drive.google.com/file/d/10iR5hKwFqAKhL3umx8muOWSRm7hs5FqX/view\n$100\n\n\n\n\n\n\n\n\n\nDate\nEvent\nSignificance\n\n\n\n\n\nLangChain\nA library to assist in the development of data-aware agentic LLM applications by including multiple LLMs combined with other sources of information. Examples include Q&A over specific documents, databases, or APIs; chatbots that can reason before responding; agents that have control over system environments to perform tasks.\n\n\n\nLLamaIndex\n\n\n\n\nGPTCache\n\n\n\n\nLocalAI\n\n\n\n\nPandasAI"
  },
  {
    "objectID": "background/index.html#the-dawn-of-open-source-ai",
    "href": "background/index.html#the-dawn-of-open-source-ai",
    "title": "Background",
    "section": "",
    "text": "Events from February 24, 2023 to April 15, 2023\n\n\nDate\nEvent\nSignificance\n\n\n\n\n2023-02-24\nMeta launches Large Language Model Meta AI (LLaMA) and open sources code without model weights.\n\n\n\n2023-03-03\nLLaMA weights are leaked and shared via torrent on the internet.\n\n\n\n2023-03-12\nArtem Andreenko is able to get LLaMA working the a Raspberry Pi\n\n\n\n2023-03-13\nStanford releases Alpaca, the first minimal working example of fine-tuning LLaMA\n\n\n\n2023-03-14\nEric Wang releases Alpaca-LoRA\n\n\n\n2023-03-18\n\n\n\n\n2023-03-19\nVicuna\n~$300\n\n\n2023-03-25\nNomic releases GPT4All\n\n\n\n2023-03-03\nCerebras uses μ-parameterization\n\n\n\n2023-03-28\nLLaMA-Adapter uses Parameter Efficient Fine Tuning (PEFT)\n\n\n\n2023-04-03\nKoala\n\n\n\n2023-04-15\nOpen Assistant https://drive.google.com/file/d/10iR5hKwFqAKhL3umx8muOWSRm7hs5FqX/view\n$100"
  },
  {
    "objectID": "background/index.html#the-era-of-democratized-ai",
    "href": "background/index.html#the-era-of-democratized-ai",
    "title": "Background",
    "section": "",
    "text": "Date\nEvent\nSignificance\n\n\n\n\n\nLangChain\nA library to assist in the development of data-aware agentic LLM applications by including multiple LLMs combined with other sources of information. Examples include Q&A over specific documents, databases, or APIs; chatbots that can reason before responding; agents that have control over system environments to perform tasks.\n\n\n\nLLamaIndex\n\n\n\n\nGPTCache\n\n\n\n\nLocalAI\n\n\n\n\nPandasAI"
  },
  {
    "objectID": "faq/index.html",
    "href": "faq/index.html",
    "title": "FAQ",
    "section": "",
    "text": "This is a question?\nThis is an answer"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Polyphemus Project",
    "section": "",
    "text": "Introduction\nThe infamous Cyclops, Polyphemus, the son of Poseidon in Greek mythology, met his downfall due to the cunning of the hero, Odysseus. When asked for his name, Odysseus cleverly responded with ‘Nobody.’ Unable to pinpoint the culprit behind his blinding, Polyphemus could not seek revenge, his actions limited to hurling a boulder aimlessly into the sea. It wasn’t until Odysseus revealed his true name that the cyclops was able to enlist his father Poseidon’s divine wrath, highlighting the power of a name.\nSimilarly, in the world of systems integration, the naming of objects is crucial. Each object must have a consistent name across various systems. While the characteristics of the object might change over space and time, the name serves as a constant identifier. With a proper name, actions can be directed effectively, whereas without it, one can only attempt hit-or-miss strategies.\nThe importance of naming extends to the realm of artificial intelligence (AI) systems. Large Language Models (LLMs) such as GPT-3, the driving force behind ChatGPT and OpenAI’s API, exemplify this. These models can perform tasks but lack the ability to recognize specific names within specialized knowledge domains. This limitation hampers their wider application, especially in fields such as observational medical research.\nIntroducing Polyphemus, a network of specialty-trained Large Language Models (LLMs), designed to overcome this limitation. Polyphemus models can not only act but also identify object names within their specialized domain. This project, a collaborative effort between the Observational Health Data Sciences and Informatics (OHDSI) community and Polyphemus, focuses on the exploration of LLMs’ application in open science and observational medical research."
  },
  {
    "objectID": "models/index.html",
    "href": "models/index.html",
    "title": "Models",
    "section": "",
    "text": "Models"
  }
]